{"word":"pretrain","priority":"★★★","meanings":[{"part_of_speech":"verb","transitivity":"vt","definition":"(機械学習モデルを)事前学習させる","english_definition":"to train a machine learning model on a general dataset before fine-tuning it for a specific task.","examples":[{"sentence":"The language model was pretrained on a large corpus of text data.","translation":"その言語モデルは大量のテキストデータで事前学習されていた。"},{"sentence":"Researchers pretrained the neural network with image recognition tasks.","translation":"研究者たちはそのニューラルネットワークを画像認識タスクで事前学習させた。"}],"collocations":["pretrain a model (モデルを事前学習させる)","pretrained weights (事前学習済みの重み)","pretraining phase (事前学習段階)"],"synonyms":["pre-train"],"antonyms":["train from scratch"]}],"etymology":{"value":"接頭辞 'pre-' (前もって) + 'train' (訓練する) の合成語。2010年代以降の深層学習の発展と共に普及した技術用語。","priority":"★☆☆"},"pronunciation":{"ipa":"/ˌpriːˈtreɪn/","syllables":"pre-train"},"inflection":{"verb_forms":{"present_simple":["pretrain","pretrains"],"past_simple":"pretrained","past_participle":"pretrained","present_participle":"pretraining"}},"usage_notes":{"explanation":"AI/機械学習分野の専門用語。大規模な汎用データで基礎的な特徴を学習させた後、特定タスク用に微調整(fine-tuning)する手法を指す。自然言語処理(NLP)やコンピュータビジョン分野で頻出。ハイフン付き(pre-train)表記も見られるが、近年はハイフンなしが主流。","priority":"★★★"},"common_mistakes":{"examples":[{"incorrect":"✗ The AI was pre-trained before the final train.","correct":"✓ The AI was pretrained before fine-tuning.","note":"'final train' より専門用語として 'fine-tuning' が適切"}],"priority":"★★☆"},"related_words":{"derivatives":["pretraining (名詞/形容詞: 事前学習)","pretrained (形容詞: 事前学習済みの)"],"technical_terms":["transfer learning (転移学習)","fine-tuning (ファインチューニング)","foundation model (基盤モデル)","self-supervised learning (自己教師あり学習)"],"priority":"★★★"},"level_frequency":{"CEFR":"C1 (専門用語)","frequency_google_ngram":"低頻度 (2010年以降急上昇)","priority":"★☆☆"},"readability_explanation":{"level":"C1","text":"「**pretrain**」はAI技術の専門用語で、機械学習モデルを特定タスク用に調整する前に、一般的なデータセットで基礎的な能力を学習させることを指します。例えば「The BERT model is pretrained on Wikipedia articles.（BERTモデルはWikipedia記事で事前学習されている）」のように使われます。技術文書や研究論文で頻繁に登場しますが、日常会話ではほとんど使われません。"},"example_sentences":[{"sentence":"Most modern NLP models are **pretrained** on massive text datasets.","translation":"現代の自然言語処理モデルの多くは大規模なテキストデータセットで事前学習されている。","type":"verb (past participle)","meaning_category":"事前学習"},{"sentence":"The **pretraining** process requires significant computational resources.","translation":"事前学習プロセスには多大な計算資源が必要となる。","type":"noun","meaning_category":"事前学習"},{"sentence":"Using **pretrained** embeddings can improve model performance.","translation":"事前学習済みの埋め込み表現を使うとモデルの性能が向上する可能性がある。","type":"adjective","meaning_category":"事前学習済み"}]}